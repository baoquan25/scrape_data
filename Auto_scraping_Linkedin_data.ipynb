{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzxM65EholuZPpLhz+I3Rm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baoquan25/scrape_data/blob/main/Auto_scraping_Linkedin_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bpZ9887SfAy"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from time import sleep\n",
        "from selenium.webdriver.common.by import By\n",
        "import csv\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver = webdriver.Chrome()\n",
        "url ='https://www.linkedin.com/login'\n",
        "driver.get(url)\n",
        "sleep(2)\n",
        "print('-finish initializing a driver')\n",
        "\n",
        "# Đọc file\n",
        "credential = open('F:/login_credential.txt')\n",
        "username = credential.readline().strip()\n",
        "password = credential.readline().strip()\n",
        "print('-finish import the login credential')\n",
        "\n",
        "# Nhập email\n",
        "email_field = driver.find_element(By.ID, 'username')\n",
        "email_field.send_keys(username)\n",
        "sleep(3)\n",
        "print('-finish key in email')\n",
        "\n",
        "# Nhập password\n",
        "password_field = driver.find_element(By.NAME, 'session_password')\n",
        "password_field.send_keys(password)\n",
        "sleep(2)\n",
        "print('-finish key in password')\n",
        "\n",
        "# CLick vào nút đăng nhập\n",
        "login_button = driver.find_element(By.XPATH, '//*[@id=\"organic-div\"]/form/div[4]/button')\n",
        "login_button.click()\n",
        "print('- Finish logging in')"
      ],
      "metadata": {
        "id": "8WvDMABzSy3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_field = driver.find_element(By.XPATH, '//*[@id=\"global-nav-typeahead\"]/input')\n",
        "\n",
        "# Input the search query to the search bar\n",
        "search_query = input('what profile do you want to scrape')\n",
        "search_field.send_keys(search_query)\n",
        "\n",
        "# Search\n",
        "search_field.send_keys(Keys.RETURN)\n",
        "print('- Finish searching')"
      ],
      "metadata": {
        "id": "jnZ8VYHkS1Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lấy 1 trang đầu\n",
        "def GetURL():\n",
        "    # Lấy mã nguồn HTML của trang hiện tại\n",
        "    page_source = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "    # Tìm tất cả các thẻ <a> có class \"app-aware-link\" và href chứa \"/in/\"\n",
        "    profiles = page_source.find_all('a', class_='ITnlIYRaRoJycfooUBNruLtOOXZuqVGU',target=lambda t: t != '_self')\n",
        "\n",
        "    # Tạo danh sách để lưu các URL hồ sơ\n",
        "    all_profile_URL = []\n",
        "\n",
        "    for profile in profiles:\n",
        "        profile_URL = profile.get('href')  # Lấy giá trị của href\n",
        "        # Kiểm tra nếu href chứa \"/in/\" (chỉ là các hồ sơ cá nhân)\n",
        "        if profile_URL and \"/in/\" in profile_URL:\n",
        "            if profile_URL not in all_profile_URL:  # Tránh trùng lặp\n",
        "                all_profile_URL.append(profile_URL)\n",
        "\n",
        "    return all_profile_URL\n",
        "\n",
        "# Gọi hàm và in kết quả\n",
        "print(GetURL())"
      ],
      "metadata": {
        "id": "j95A6HFNS4h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GetURLsonPages():\n",
        "    input_page = int(input('How many pages you want scrape'))\n",
        "    URLs_all_page = []\n",
        "    for page in range(input_page):\n",
        "        URLs_one_page = GetURL()\n",
        "        sleep(2)\n",
        "\n",
        "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
        "        sleep(2)\n",
        "\n",
        "        next_button = driver.find_element(By.CLASS_NAME, 'artdeco-pagination__button--next')\n",
        "        next_button.click()\n",
        "        sleep(2)\n",
        "\n",
        "        URLs_all_page.extend(URLs_one_page)\n",
        "    return URLs_all_page\n",
        "\n",
        "\n",
        "# Lấy danh sách URL\n",
        "URLs_all_page = GetURLsonPages()\n",
        "\n",
        "# Mở file CSV để ghi dữ liệu\n",
        "with open('output.csv', 'w', newline='', encoding='utf-8-sig') as file_output:\n",
        "    headers = ['Name', 'Job title', 'Location', 'URL']\n",
        "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n', fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Lặp qua tất cả các URL và lấy thông tin\n",
        "    for idx, linkedin_URL in enumerate(URLs_all_page, start=1):\n",
        "\n",
        "        # Mở URL trên trình duyệt\n",
        "        driver.get(linkedin_URL)\n",
        "\n",
        "        # Lấy mã nguồn HTML của trang\n",
        "        page_source = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "\n",
        "        info_div = page_source.find('div', class_ ='mt2 relative')\n",
        "        if not info_div:\n",
        "            continue  # Bỏ qua URL này và chuyển sang URL tiếp theo\n",
        "\n",
        "\n",
        "        # Tìm thẻ h1 có tên nhân viên\n",
        "        name = info_div.find('h1').get_text().strip()\n",
        "        print('tên nhân viên: ',name)\n",
        "\n",
        "        # tìm nghề nghiệp\n",
        "        job = info_div.find('div', class_='text-body-medium break-words').get_text().strip()\n",
        "        print('nghề nghiệp: ',job)\n",
        "\n",
        "        #tìm vị trí\n",
        "        location = info_div.find('span', class_='text-body-small inline t-black--light break-words').get_text().strip()\n",
        "        print('vị trí: ',location)\n",
        "\n",
        "        #in đường link\n",
        "        print('URL :',linkedin_URL)\n",
        "        print('-' * 50)\n",
        "\n",
        "        writer.writerow({'Name': name, 'Job title': job, 'Location': location, 'URL': linkedin_URL})\n",
        "\n",
        "print(\"Dữ liệu đã được ghi vào output.csv.\")"
      ],
      "metadata": {
        "id": "L0p37zIQS5Cl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}